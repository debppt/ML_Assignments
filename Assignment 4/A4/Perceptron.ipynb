{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itAidXsCy3qv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/diabetes.csv')"
      ],
      "metadata": {
        "id": "R7wV2CPUzI2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = data.drop('Outcome',axis = 1)\n",
        "Y_data = data['Outcome']"
      ],
      "metadata": {
        "id": "Dr1MHA-1zKYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X_data,Y_data,test_size = 0.2,random_state = 42)"
      ],
      "metadata": {
        "id": "6VYFBY7OzO3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler =  StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "933UrOcizQjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PERCEPTRON LIBRARY IMPLEMENTATION"
      ],
      "metadata": {
        "id": "suhkNLaM2k_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perceptron_model = Perceptron(max_iter = 2000, tol = 1e-3, random_state = 4)\n",
        "perceptron_model.fit(X_train_scaled,y_train)\n",
        "y_pred_perceptron = perceptron_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "jWrrR1zAzSYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test,y_pred_perceptron)\n",
        "precision = precision_score(y_test,y_pred_perceptron)\n",
        "recall = recall_score(y_test,y_pred_perceptron)\n",
        "f1 = f1_score(y_test,y_pred_perceptron)"
      ],
      "metadata": {
        "id": "iaoCqyMgzvXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy of Perceptron Model is: {accuracy}\")\n",
        "print(f\"Precision of Perceptron Model is: {precision}\")\n",
        "print(f\"Recall of Perceptron Model is: {recall}\")\n",
        "print(f\"F1 Score of Perceptron Model is: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUH2ReqDz8NY",
        "outputId": "4963ff75-1d58-44e7-d24a-7f0221f0ac44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Perceptron Model is: 0.7662337662337663\n",
            "Precision of Perceptron Model is: 0.6507936507936508\n",
            "Recall of Perceptron Model is: 0.7454545454545455\n",
            "F1 Score of Perceptron Model is: 0.6949152542372882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PERCEPTRON CUSTOM IMPLEMENTATION"
      ],
      "metadata": {
        "id": "RJwj6bmc2g6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleLayerPerceptron:\n",
        "  def __init__(self,my_weights,my_bias,learning_rate = 0.05,max_iter = 2000):\n",
        "    self.weights = my_weights\n",
        "    self.bias = my_bias\n",
        "    self.learning_rate = learning_rate\n",
        "    self.max_iter = max_iter\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    y = np.where(y == 0, -1, y)\n",
        "    for _ in range(self.max_iter):\n",
        "      for idx,x_i in enumerate(X):\n",
        "        linear_output = np.dot(x_i,self.weights) + self.bias\n",
        "        y_predicted = 1 if linear_output > 0 else -1\n",
        "\n",
        "        if(y_predicted != y[idx]):\n",
        "          self.weights+=self.learning_rate*y[idx]*x_i\n",
        "          self.bias+=self.learning_rate*y[idx]\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    X_test = np.array(X_test)\n",
        "    linear_prediction = np.dot(X_test, self.weights) + self.bias\n",
        "    linear_prediction = np.where(linear_prediction > 0, 1, -1)\n",
        "\n",
        "    return linear_prediction\n",
        "\n",
        "  @staticmethod\n",
        "  def metrics(y,y_pred):\n",
        "    y = np.array(y)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    tp = np.sum((y_pred == 1) & (y == 1))\n",
        "    tn = np.sum((y_pred == -1) & (y == -1))\n",
        "    fp = np.sum((y_pred == 1) & (y == -1))\n",
        "    fn = np.sum((y_pred == -1) & (y == 1))\n",
        "\n",
        "    accuracy = (tp + tn) / len(y)\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return accuracy, precision, recall, f1_score\n"
      ],
      "metadata": {
        "id": "q0XqhH0O2jhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(30)\n",
        "w = np.random.rand(X_train.shape[1])\n",
        "b = np.random.rand()"
      ],
      "metadata": {
        "id": "HnaWhMpV9r7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40hahVJ_b6T5",
        "outputId": "77302566-8763-4825-bead-9d2d27096ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.64414354, 0.38074849, 0.66304791, 0.16365073])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpZm8mEab6-j",
        "outputId": "3b4a5959-1d95-4a2c-8aaa-1da383010263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9626078136743187"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model = SingleLayerPerceptron(w,b)\n",
        "\n",
        "custom_model.fit(X_train_scaled,y_train)"
      ],
      "metadata": {
        "id": "02l8ix-Sb5g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlg2WB7Ub7mt",
        "outputId": "254f6a88-9403-4df4-911c-c33936bcb11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08976902, 0.04398389, 0.13984575, 0.03377206])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QlbA0PIcCdE",
        "outputId": "d1bca5dc-106a-4253-d2f0-69d60c1f7ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.03739218632568167"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = custom_model.predict(X_test_scaled)\n",
        "y_test = np.where(y_test == 0, -1, y_test)\n",
        "accuracy, precision, recall, f1_score_custom = custom_model.metrics(y_pred,y_test)\n",
        "print(f\"Accuracy of Custom Perceptron model is {accuracy}\")\n",
        "print(f\"Precision of Custom Perceptron model is {precision}\")\n",
        "print(f\"Recall of Custom Perceptron model is {recall}\")\n",
        "print(f\"F1 Score of Custom Perceptron model is {f1_score_custom}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5NhzP-aFgrH",
        "outputId": "0918ba8e-585a-4b78-c372-204539d08faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Custom Perceptron model is 0.7077922077922078\n",
            "Precision of Custom Perceptron model is 0.7090909090909091\n",
            "Recall of Custom Perceptron model is 0.5735294117647058\n",
            "F1 Score of Custom Perceptron model is 0.6341463414634145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('perceptron_model.pkl','wb') as file:\n",
        "  pickle.dump(perceptron_model,file)"
      ],
      "metadata": {
        "id": "X2u1o1V1NI5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('custom_perceptron_model.pkl','wb') as file:\n",
        "  pickle.dump(custom_model,file)"
      ],
      "metadata": {
        "id": "kAmT0R5iyL1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.mean_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs6EdAxW9SQV",
        "outputId": "f8d878ff-7594-4e96-ae90-b08b1278977c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([120.85504886,  81.43811075,  31.98338762,  32.90716612])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.scale_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J6PmRhnEJag",
        "outputId": "a260fb29-4f5c-412a-bddc-2aa8b821b0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 32.00895893, 116.14014299,   7.73431907,  11.49406506])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Fold cross verification:-"
      ],
      "metadata": {
        "id": "0Tn2XC7t4AfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42) # Using 5 folds for this example"
      ],
      "metadata": {
        "id": "dPAmC5-30Q0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "accuracy_scores_library = []\n",
        "precision_scores_library = []\n",
        "recall_scores_library = []\n",
        "f1_scores_library = []\n",
        "\n",
        "for train_index, test_index in kfold.split(X_data):\n",
        "    X_train, X_test = X_data.iloc[train_index], X_data.iloc[test_index]\n",
        "    y_train, y_test = Y_data.iloc[train_index], Y_data.iloc[test_index]\n",
        "\n",
        "    # Scale data within each fold\n",
        "    scaler = StandardScaler()  # Create a new scaler for each fold\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    perceptron_model = Perceptron(max_iter=2000, tol=1e-3, random_state=4)\n",
        "    perceptron_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred = perceptron_model.predict(X_test_scaled)\n",
        "\n",
        "    accuracy_scores_library.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores_library.append(precision_score(y_test, y_pred))\n",
        "    recall_scores_library.append(recall_score(y_test, y_pred))\n",
        "    f1_scores_library.append(f1_score(y_test, y_pred))\n",
        "\n",
        "# Calculate and print average metrics:\n",
        "print(\"Library Perceptron - Average Metrics:\")\n",
        "print(f\"Accuracy: {np.mean(accuracy_scores_library)}\")\n",
        "print(f\"Precision: {np.mean(precision_scores_library)}\")\n",
        "print(f\"Recall: {np.mean(recall_scores_library)}\")\n",
        "print(f\"F1 Score: {np.mean(f1_scores_library)}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bedYoCcc2LmZ",
        "outputId": "e1f242f7-f1a1-47c3-fc05-c7da364c9e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Library Perceptron - Average Metrics:\n",
            "Accuracy: 0.7201171377641966\n",
            "Precision: 0.5419148936170213\n",
            "Recall: 0.4142080511889155\n",
            "F1 Score: 0.44442554529694334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance metrics for Naive bayes is better since Perceptron models prefer linearly separable data."
      ],
      "metadata": {
        "id": "NUwOTZ408oFj"
      }
    }
  ]
}